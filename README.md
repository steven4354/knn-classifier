# knn-classifier

So far we've covered learning via probability (naive Bayes) and learning via errors (regression). Here we'll cover learning via similarity. This means we look for the datapoints that are most similar to the observation we are trying to predict.

Nearest neighbor - grab the point that is closest and return the "Y" value of that

K Nearest neighbor - grab K nearest points and return the "Y" that appears the most frequently out of the K points

See jupyter notebook for more detailed explanation
